{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f8bf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scortesg/opt/anaconda3/envs/rp_fall2022/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48c23b",
   "metadata": {},
   "source": [
    "#### Data creation problem formulation\n",
    "\n",
    "A dummie dataset is going to be created, from now on features is going to be a column of the dataset. Levels will be the semantic feature i.e sex and estrata the posible value for a level, i.e male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b9ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"german_credit_data.csv\", index_col=0)\n",
    "data_labels = pd.read_csv(\"german_credit.csv\")\n",
    "data_dummies = pd.get_dummies(data[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac40544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies[[\"free\", \"own\", \"rent\"]] = pd.get_dummies(data[\"Housing\"])\n",
    "data_dummies[[\"little\", \"moderate\", \"quite rich\", \"rich\"]] = pd.get_dummies(data[\"Saving accounts\"])\n",
    "data_dummies[[\"Age Bucket A\", \"Age Bucket B\", \"Age Bucket c\", \"Age Bucket D\"]] = pd.get_dummies(pd.cut(data.Age, [18, 25, 45, 60, 75]))\n",
    "data_dummies[\"Creditability\"] = data_labels[\"Creditability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88497825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['female', 'male', 'free', 'own', 'rent', 'little', 'moderate',\n",
       "       'quite rich', 'rich', 'Age Bucket A', 'Age Bucket B', 'Age Bucket c',\n",
       "       'Age Bucket D', 'Creditability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a99c13",
   "metadata": {},
   "source": [
    "Now the dataset is artificially biased, in this particular case only one forth of the males with good credit score are taken and one forth of the females with a ba\n",
    "d one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3261221",
   "metadata": {},
   "outputs": [],
   "source": [
    "females = data_dummies[data_dummies.female == 1]\n",
    "females_good = females[females.Creditability == 1]\n",
    "females_bad = females[females.Creditability == 0]\n",
    "\n",
    "males = data_dummies[data_dummies.female == 0]\n",
    "males_good = males[males.Creditability == 1]\n",
    "males_bad = males[males.Creditability == 0]\n",
    "\n",
    "ma_good_sample = males_good.sample(frac = 0.25)\n",
    "fem_bad_sample = females_bad.sample(frac = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0b8ed",
   "metadata": {},
   "source": [
    "from now on the random variable $A$ will denote apperaing or not in this datatset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746db53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_skewed_data = pd.concat([ma_good_sample, males_bad, females_good, fem_bad_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401288c",
   "metadata": {},
   "source": [
    "### Implementation of `Pending cool name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4bb73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is alist of all levels of the dataset: each one as a list containing its corresponding estrata\n",
    "levels = [['female', 'male'],['free', 'own', 'rent'], ['little', 'moderate',\n",
    "       'quite rich', 'rich'], ['Age Bucket A', 'Age Bucket B', 'Age Bucket c',\n",
    "       'Age Bucket D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee53daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weight_matrix(levels: List[List]):\n",
    "    \"\"\"\n",
    "    Creates all posible combinations of dummie variables from\n",
    "    a list of levels.\n",
    "    \n",
    "    Example:\n",
    "    From [[apple, orange], [juice, jam, salad]]\n",
    "    \n",
    "    returns: \n",
    "    [[1,0,1,0, 0],[1,0, 0, 1, 0],[1,0, 0,0, 1]\n",
    "    [0,1,1,0, 0],[0,1,0,1, 0],[0,1,0,0, 1]]\n",
    "    \"\"\"\n",
    "    weight_features = []\n",
    "    index = 0\n",
    "    vectors = []\n",
    "    for feature in levels:\n",
    "        number_levels = len(feature)\n",
    "        diagonal = torch.ones([number_levels])\n",
    "        one_hot_vectors = torch.diag(diagonal)\n",
    "        vectors.append(one_hot_vectors)\n",
    "    for pair in itertools.product(*vectors):\n",
    "        weight_features.append(torch.cat(pair))\n",
    "    weight_features = torch.stack(weight_features, axis=0)\n",
    "    return weight_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d04f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_counts(data : pd.DataFrame, levels: List[List], target:str):\n",
    "    \"\"\"\n",
    "    Given a dummie variable dataset it return a matrix counts\n",
    "    from all posible combinations of features\n",
    "    \"\"\"\n",
    "    shape = [0 for i in range(len(levels) + 1)]        \n",
    "    # 2 comes from the response variable Y in this case binary\n",
    "    shape[0] = 2\n",
    "    \n",
    "    for index, level in enumerate(levels):\n",
    "        number_levels = len(level)\n",
    "        shape[index + 1] = number_levels\n",
    "        \n",
    "    count = torch.zeros(shape)\n",
    "    for _, row in data.iterrows():\n",
    "        position = [0 for i in range(len(levels) + 1)]\n",
    "        position[0] = row[target]\n",
    "        \n",
    "        for index, level in enumerate(levels):\n",
    "            for index_j, feature in enumerate(level):\n",
    "                if row[feature] == 1:\n",
    "                   position[index + 1] = index_j\n",
    "        count[tuple(position)] += 1\n",
    "    # Machetimbis para que despu√©s no me estallen los gradientes\n",
    "    count[count == 0] = 0.00001\n",
    "    return count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ff48f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = build_counts(sex_skewed_data, levels, \"Creditability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca6530ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_features = create_weight_matrix(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d94de04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_0 = counts[0]\n",
    "data_count_1 = counts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc443ef1",
   "metadata": {},
   "source": [
    "# Watch out\n",
    "Here is where most of the meat is. The method is based in building restrictions for an optimization problem that will make the observed data consistent with some ground truth value (i.e some data taken from the real world). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a17383d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 14)\n",
      "(209, 14)\n",
      "(219, 14)\n",
      "(481, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/kkyvc6j528n8bbnjl0xkn20r0000gp/T/ipykernel_18076/1081995785.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(data_dummies[data_dummies[\"Creditability\"] == 0][data_dummies[\"female\"] == 1].shape)\n",
      "/var/folders/pp/kkyvc6j528n8bbnjl0xkn20r0000gp/T/ipykernel_18076/1081995785.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(data_dummies[data_dummies[\"Creditability\"] == 0][data_dummies[\"male\"] == 1].shape)\n",
      "/var/folders/pp/kkyvc6j528n8bbnjl0xkn20r0000gp/T/ipykernel_18076/1081995785.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(data_dummies[data_dummies[\"Creditability\"] == 1][data_dummies[\"female\"] == 1].shape)\n",
      "/var/folders/pp/kkyvc6j528n8bbnjl0xkn20r0000gp/T/ipykernel_18076/1081995785.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(data_dummies[data_dummies[\"Creditability\"] == 1][data_dummies[\"male\"] == 1].shape)\n"
     ]
    }
   ],
   "source": [
    "print(data_dummies[data_dummies[\"Creditability\"] == 0][data_dummies[\"female\"] == 1].shape)\n",
    "print(data_dummies[data_dummies[\"Creditability\"] == 0][data_dummies[\"male\"] == 1].shape)\n",
    "print(data_dummies[data_dummies[\"Creditability\"] == 1][data_dummies[\"female\"] == 1].shape)\n",
    "print(data_dummies[data_dummies[\"Creditability\"] == 1][data_dummies[\"male\"] == 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c64e9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand made ground truth restricitions\n",
    "b0 = np.array([91, 209])\n",
    "b1 = np.array([219, 481])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6bdade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_strata_counts_matrix(weight_features: torch.Tensor, counts: torch.Tensor, level: List[str]):\n",
    "    \"\"\"Builds linear restrictions for a convex opt problem.\n",
    "    \n",
    "    This method build a Matrix with counts by combination of strata,\n",
    "    It will return two matrixes each one associated to the idividuals\n",
    "    with y=1 or y=1:\n",
    "    \n",
    "    A_1 (a_{ij}), a_{ij} is the number of observations in the dataset\n",
    "    such that y=1 x_i = 1 and x_j =1.\n",
    "    \n",
    "    A_0 (a_{ij}), a_{ij} is the number of observations in the dataset\n",
    "    such that y=1 x_i = 1 and x_j =1.\n",
    "    \n",
    "    Note that unlike i, j is fixed, in the code outside this method\n",
    "    varies trough female and male\n",
    "    \n",
    "    returns A_0, A_1\n",
    "    \"\"\"\n",
    "    _, features = weight_features.shape\n",
    "    level_size = len(level)\n",
    "    # This should be associated with the y?\n",
    "    y_0_ground_truth = torch.zeros(level_size, features)\n",
    "    y_1_ground_truth = torch.zeros(level_size, features)\n",
    "    \n",
    "    data_count_0 = counts[0]\n",
    "    data_count_1 = counts[1]\n",
    "    \n",
    "    for level in range(level_size):\n",
    "        # Flaw here only works with the first level.\n",
    "        t = data_count_0[level].flatten().unsqueeze(1)\n",
    "        t_ = data_count_1[level].flatten().unsqueeze(1)\n",
    "\n",
    "        features = weight_features[level*t.shape[0]:(level + 1)*t.shape[0]]\n",
    "        features_ = weight_features[level*t_.shape[0]:(level + 1)*t_.shape[0]]\n",
    "        \n",
    "        y_0_ground_truth[level] = (features*t).sum(dim=0)\n",
    "        y_1_ground_truth[level] = (features_*t_).sum(dim=0)\n",
    "\n",
    "    return y_0_ground_truth, y_1_ground_truth\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a044dbb",
   "metadata": {},
   "source": [
    "This method was built for ease of computation, we wanted something that can be written in terms of matrix multiplications and slices thus taking advantage of DL frameworks paralelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7417f5b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A0, A1 = build_strata_counts_matrix(weight_features, counts, [\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9fd529",
   "metadata": {},
   "source": [
    "### Optimization part\n",
    "Let it rip!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc65e371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5513608455657959 -0.6092672537573116 0.9049572944641113\n",
      "-0.5513609647750854 -0.6092674256156512 0.9049572348594666\n",
      "-0.5513609051704407 -0.609267359751053 0.9049572348594666\n",
      "-0.5513607859611511 -0.6092673082801493 0.904957115650177\n",
      "-0.5513606071472168 -0.6092671106863283 0.904957115650177\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m alpha\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x\u001b[38;5;241m.\u001b[39mvalue)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     22\u001b[0m weights_y1 \u001b[38;5;241m=\u001b[39m (weight_features\u001b[38;5;129m@alpha\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mdata_count_0\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 23\u001b[0m weights_y0 \u001b[38;5;241m=\u001b[39m (\u001b[43mweight_features\u001b[49m\u001b[38;5;129;43m@alpha\u001b[39;49m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mdata_count_1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     25\u001b[0m weighted_counts_1 \u001b[38;5;241m=\u001b[39m weights_y1\u001b[38;5;241m*\u001b[39mdata_count_1\n\u001b[1;32m     26\u001b[0m weighted_counts_0 \u001b[38;5;241m=\u001b[39m weights_y0\u001b[38;5;241m*\u001b[39mdata_count_0\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp_fall2022/lib/python3.10/site-packages/torch/fx/traceback.py:57\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m current_stack\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp_fall2022/lib/python3.10/traceback.py:213\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp_fall2022/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp_fall2022/lib/python3.10/traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    376\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 379\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp_fall2022/lib/python3.10/site-packages/IPython/core/compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp_fall2022/lib/python3.10/linecache.py:65\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[1;32m     64\u001b[0m     entry \u001b[38;5;241m=\u001b[39m cache[filename]\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(entry) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;66;03m# lazy cache entry, leave it lazy.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     size, mtime, lines, fullname \u001b[38;5;241m=\u001b[39m entry\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "alpha = torch.rand(weight_features.shape[1], requires_grad=True)\n",
    "W = np.unique(weight_features.numpy(), axis=0)\n",
    "tol = 0.00000001\n",
    "\n",
    "optim = torch.optim.Adam([alpha], lr=5e-2)\n",
    "\n",
    "for iteration in range(10000):\n",
    "    x = cp.Variable(alpha.shape[0])\n",
    "    alpha_fixed = alpha.squeeze().detach().numpy()\n",
    "    A_0 = A0.numpy()\n",
    "    A_1 = A1.numpy()\n",
    "\n",
    "    objective = cp.sum_squares(x - alpha_fixed)\n",
    "    # With the two rstrictions (as it should) the problem is infeasible\n",
    "    restrictions = [W@x >=1, A_0@ x == b0]\n",
    "    prob = cp.Problem(cp.Minimize(objective), restrictions)\n",
    "    prob.solve()\n",
    "\n",
    "    #\n",
    "    alpha.data = torch.tensor(x.value).float()\n",
    "    weights_y1 = (weight_features@alpha).reshape(*data_count_0.shape)\n",
    "    weights_y0 = (weight_features@alpha).reshape(*data_count_1.shape)\n",
    "    \n",
    "    weighted_counts_1 = weights_y1*data_count_1\n",
    "    weighted_counts_0 = weights_y0*data_count_0\n",
    "\n",
    "    sex = 1\n",
    "    sex_base = 0\n",
    "    \n",
    "    probs = weighted_counts_1/(weighted_counts_1 + weighted_counts_0)\n",
    "\n",
    "    total_weight_count = weighted_counts_1[sex] + weighted_counts_0[sex]\n",
    "    # Here is the g-formula, The assertation now is sex\n",
    "    diff = ((probs[sex] - probs[sex_base])*total_weight_count/total_weight_count.sum()).sum()\n",
    "    total_weighted_count_base =  weighted_counts_1[sex_base] + weighted_counts_0[sex_base]\n",
    "    base = (probs[sex_base]*total_weighted_count_base/total_weighted_count_base.sum()).sum()\n",
    "    \n",
    "    loss = diff\n",
    "    if iteration % 500 == 0:\n",
    "        print(diff.item(), diff.item()/base.item(), base.item())\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c73a5bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(weight_features[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ac705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rp_fall2022]",
   "language": "python",
   "name": "conda-env-rp_fall2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
